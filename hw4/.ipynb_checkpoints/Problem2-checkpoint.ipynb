{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Problem-2\" data-toc-modified-id=\"Problem-2-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Problem 2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import\" data-toc-modified-id=\"Import-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Import</a></span></li><li><span><a href=\"#Loading-dataset\" data-toc-modified-id=\"Loading-dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Loading dataset</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Visualization\" data-toc-modified-id=\"Visualization-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Visualization</a></span></li><li><span><a href=\"#Dataset-Embedding\" data-toc-modified-id=\"Dataset-Embedding-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Dataset Embedding</a></span></li><li><span><a href=\"#Simple-MLP\" data-toc-modified-id=\"Simple-MLP-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Simple MLP</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-instantiation\" data-toc-modified-id=\"Model-instantiation-1.7.1\"><span class=\"toc-item-num\">1.7.1&nbsp;&nbsp;</span>Model instantiation</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-1.7.2\"><span class=\"toc-item-num\">1.7.2&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Test\" data-toc-modified-id=\"Test-1.7.3\"><span class=\"toc-item-num\">1.7.3&nbsp;&nbsp;</span>Test</a></span></li><li><span><a href=\"#Visualization\" data-toc-modified-id=\"Visualization-1.7.4\"><span class=\"toc-item-num\">1.7.4&nbsp;&nbsp;</span>Visualization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Confusion-matrix\" data-toc-modified-id=\"Confusion-matrix-1.7.4.1\"><span class=\"toc-item-num\">1.7.4.1&nbsp;&nbsp;</span>Confusion matrix</a></span></li><li><span><a href=\"#Visualizing-samlpes\" data-toc-modified-id=\"Visualizing-samlpes-1.7.4.2\"><span class=\"toc-item-num\">1.7.4.2&nbsp;&nbsp;</span>Visualizing samlpes</a></span></li></ul></li></ul></li><li><span><a href=\"#MLP-with-Dropout\" data-toc-modified-id=\"MLP-with-Dropout-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>MLP with Dropout</a></span><ul class=\"toc-item\"><li><span><a href=\"#Question\" data-toc-modified-id=\"Question-1.8.1\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>Question</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Please fill todo parts of this code. \n",
    "You can change any part of the code that you think it is needed but we do not suggest that. \n",
    "\n",
    "After you filled the todo parts please run the whole network one time and then upload your results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "Import your required libraries in this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# do not change these three lines\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "# datasets\n",
    "trainset = datasets.FashionMNIST('./data', download=True, train=True, transform=transform)\n",
    "testset = datasets.FashionMNIST('./data', download=True, train=False,transform=transform)\n",
    "\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./simple-MLP')\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCH = 20\n",
    "sample_size = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, network, criterion):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.optimizer = optim.Adam(self.network.parameters(), lr=1e-3)\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "    def calculate_accuracy(self, outputs, true_labels):\n",
    "        '''\n",
    "        This method calculate the accuracy of the classification.\n",
    "        \n",
    "        Inputs:\n",
    "            outputs: outputs of the network \n",
    "            true_labels: true label of the samples\n",
    "        Outputs:\n",
    "            accuracy: accuracy of the classificatoin (# of true classified samlpes/# of all samples)\n",
    "        '''\n",
    "        # todo: Put your code here\n",
    "        return accuracy\n",
    "        \n",
    "    def fit(self, train_data, batch_size, n_epoch, tensorboard_writer=None):\n",
    "        '''\n",
    "        This method trains your model. \n",
    "        \n",
    "        Inputs: \n",
    "            train_data: training dataset (samples, labels)\n",
    "            batch_size: batch size for training \n",
    "            n_epoch: # of epochs that the training should be done. \n",
    "            tensorboard_writer: writer of tensorboard for logging training information. \n",
    "        '''\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        n_iter = 0\n",
    "        self.train()\n",
    "        for epoch in range(n_epoch):\n",
    "            for i, data in enumerate(train_loader):\n",
    "                # todo: Put your code here\n",
    "                if tensorboard_writer is not None:\n",
    "                    tensorboard_writer.add_scalar('Loss/train', loss, n_iter)\n",
    "                    tensorboard_writer.add_scalar('Accuracy/train', accuracy, n_iter)\n",
    "                    n_iter += 1\n",
    "            print('Epoch {}:'.format(epoch))\n",
    "            self.evaluate(train_data, trainset.data.size(0))\n",
    "    \n",
    "    def evaluate(self, evaluation_data, batch_size):\n",
    "        '''\n",
    "        This method evaluate the model on the inputs data for its first batch. \n",
    "        Note: this method evaluate only the first batch of the data, so if you want to evaluate \n",
    "        whole the dataset, batch size should be equal to the datset size.\n",
    "        Inputs: \n",
    "            evaluation_data: the dataset that should be evaluated (samples, labels)\n",
    "            batch_size: size of the batch that should be evaluated\n",
    "        '''\n",
    "        self.eval()\n",
    "        evaluation_loader = DataLoader(evaluation_data, batch_size=batch_size, shuffle=False)\n",
    "        inputs, labels = iter(evaluation_loader).next()\n",
    "        # todo: Put your code here\n",
    "        print('Accuracy: {}'.format(accuracy))\n",
    "        \n",
    "    def predict(self, prediction_data, batch_size):\n",
    "        '''\n",
    "        This method predict the model output for input dataset.\n",
    "        Note: this method predict only the first batch of the data, so if you want to evaluate \n",
    "        whole the dataset, batch size should be equal to the datset size.\n",
    "        Inputs: \n",
    "            prediction_data: prediction dataset (samples, labels)\n",
    "            batch_size: size of the batch that should be predicted\n",
    "            \n",
    "        Outputs: \n",
    "            labels: true labels of the samlpes (batch_size, 1)\n",
    "            prediction_labels: predicted labels of the samlpes (batch_size, 1)\n",
    "            prediction probs: predicte probs for the class with highest probability (batch_size, 1)\n",
    "        '''\n",
    "        self.eval()\n",
    "        prediction_loader = DataLoader(prediction_data, batch_size=batch_size, shuffle=False)\n",
    "        inputs, labels = iter(prediction_loader).next()\n",
    "        # todo: Put your code here\n",
    "        return labels, prediction_labels, prediction_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "**Help**: you can read about confusion matrix [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_mat(true_labels, predicted_labels):\n",
    "    '''\n",
    "    This function take true and predicted labels and plot the confusion matrix. \n",
    "    '''\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    # todo: Put your code here\n",
    "\n",
    "    return fig\n",
    "\n",
    "def plot_classes_preds(images, prediction_probs, prediction_labels, true_labels, num_sample, classes):\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    perm = torch.randperm(len(images))\n",
    "    for idx in np.arange(num_sample):\n",
    "        ax = fig.add_subplot(1, num_sample, idx+1, xticks=[], yticks=[])\n",
    "        plt.imshow(images[perm][idx])\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[prediction_labels[perm][idx]],\n",
    "            prediction_probs[perm][idx] * 100.0,\n",
    "            classes[true_labels[perm][idx]]),\n",
    "                    color=(\"green\" if prediction_labels[perm][idx]==true_labels[perm][idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Embedding\n",
    "This part embeds your input features in 2 or 3 dimensions. You can see the results in the tensorboard log. \n",
    "You do **not** need to do anything in this part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n_random(data, labels, n=100):\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features, metadata=class_labels, label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP\n",
    "This network has 3 hidden layers and one output layer. \n",
    "\n",
    "**hidden layers**\n",
    "* linear layer with 256 neurons and tanh activation function.\n",
    "* linear layer with 128 neurons and tanh activation function.\n",
    "* linear layer with 100 neurons and tanh activation function.\n",
    "\n",
    "**Output layer**\n",
    "* 10 neurons output with softmax activation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: define the simple mlp network. \n",
    "network = ...\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "simple_MLP_model = MLPModel(network, criterion)\n",
    "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "images, labels = iter(train_loader).next()\n",
    "writer.add_graph(network, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_MLP_model.fit(trainset, BATCH_SIZE, N_EPOCH, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model performance on test set: ')\n",
    "simple_MLP_model.evaluate(testset, testset.data.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, prediction_labels, prediction_probs = simple_MLP_model.predict(testset, testset.data.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_plot = plot_conf_mat(true_labels, prediction_labels)\n",
    "writer.add_figure('Confusion matrix', conf_mat_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing samlpes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images_plot = plot_classes_preds(testset.data, prediction_probs, prediction_labels, \n",
    "                                        true_labels, sample_size, classes)\n",
    "writer.add_figure('Prediction vs Labels', sample_images_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir './simple-MLP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP with Dropout\n",
    "This network is the same as the simple MLP model except that has a dropout layer with p=0.4 after linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: define the simple mlp network. \n",
    "network = ...\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "MLP_with_dropout_model = MLPModel(network, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_with_dropout_model.fit(trainset, BATCH_SIZE, N_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_with_dropout_model.evaluate(testset, testset.data.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "* What is the effect of dropout? (Search about this in the internet and breifly describe it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
